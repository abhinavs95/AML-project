{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Google drive/columbia sem2/AML/dataset\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "def itemize(data):\n",
    "    _,indx = np.unique(data,return_index=True)\n",
    "    u = data[np.sort(indx)]\n",
    "    n_data = u.shape[0]\n",
    "    new_indx = np.arange(n_data)\n",
    "    d = dict(zip(u,new_indx))\n",
    "    data_indx = np.zeros(data.shape, dtype=np.int32)\n",
    "    for i in range(data_indx.shape[0]):\n",
    "        data_indx[i] = d[data[i]]\n",
    "    return data_indx, n_data\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv('review.csv')\n",
    "    data = data.drop(['funny', 'review_id', 'text', 'date', 'useful', 'cool'], axis=1)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    rows, cols, stars = np.array(data['user_id']), np.array(data['business_id']), np.array(data['stars'],dtype=np.uint8)\n",
    "    # itemize users and items\n",
    "    row_indx, n_users = itemize(rows)\n",
    "    col_indx, n_items = itemize(cols)\n",
    "    return scipy.sparse.csr_matrix((stars,(row_indx, col_indx)), dtype=np.uint8, shape=(n_users,n_items))\n",
    "\n",
    "\n",
    "R = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l,w  = R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submitted by Isht Dwivedi, UNI id2303\n",
    "# Advanced Machine Learning for Personalization, HomeWork 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import timeit\n",
    "from scipy.sparse.linalg import norm\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "save_dir = 'objF'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    \"\"\"\n",
    "    function to dumb grid search matrix to file\n",
    "    \"\"\"\n",
    "    with open(save_dir+'/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    \"\"\"\n",
    "    function to load grid search matrix from file\n",
    "    \"\"\"\n",
    "    with open(save_dir+'/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    This function reads the input csv file and stores data in a list\n",
    "    \"\"\"\n",
    "    ratings_lines = open(filename).readlines()\n",
    "    f = []\n",
    "    for line in ratings_lines[1:]:\n",
    "        f.append(int(line.split(',')[1]))\n",
    "    f = list(set(f))\n",
    "    c = 0\n",
    "    m2i = {}\n",
    "    for i in f:\n",
    "        m2i[i]=c\n",
    "        c+=1\n",
    "\n",
    "    return m2i,ratings_lines\n",
    "\n",
    "\n",
    "def split_train_test(ratings_lines):\n",
    "    \"\"\"\n",
    "    This function splits the data into train and test. For each user, half of the data \n",
    "    goes into the train set and the other half goes into the test set\n",
    "    \"\"\"\n",
    "    user_ratings = {}\n",
    "    for line in ratings_lines[1:]:\n",
    "        parts = line.split(',')\n",
    "        if int(parts[0])-1 not in user_ratings:\n",
    "            #userId,movieId,rating,timestamp\n",
    "            user_ratings[int(parts[0])-1] = [(   m2i[int(parts[1])],float(parts[2])   )]\n",
    "        else:\n",
    "            user_ratings[int(parts[0])-1].append( ( m2i[int(parts[1])], float(parts[2]) )  )\n",
    "\n",
    "    for key in user_ratings.keys():\n",
    "        shuffle(user_ratings[key])\n",
    "    R_train = lil_matrix((l, w))\n",
    "    R_test = lil_matrix((l, w))\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for userID0 in user_ratings.keys():\n",
    "        k = int(len(user_ratings[userID0])/2)\n",
    "        for i in range(k):\n",
    "            R_train[userID0,user_ratings[userID0][i][0]]=user_ratings[userID0][i][1]\n",
    "            train_list.append((userID0,user_ratings[userID0][i][0]))\n",
    "        for i in range(k,len(user_ratings[userID0])):\n",
    "            R_test[userID0,user_ratings[userID0][i][0]]=user_ratings[userID0][i][1]\n",
    "            test_list.append((userID0,user_ratings[userID0][i][0]))\n",
    "            \n",
    "    return train_list,test_list,R_train,R_test,user_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_train = R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(R_train,train_list,r,max_iter,lam,lr):\n",
    "    \"\"\"\n",
    "    this function does SGD on the train data and return the matrix factorization\n",
    "    Input to this function are the max. number of epocs to train, the learning rate, the regularization weigt and the train data\n",
    "    \"\"\"\n",
    "    p = np.random.normal(0,1./r, (l,r)).astype(dtype=np.float128)\n",
    "    q = np.random.normal(0,1./r, (r,w)).astype(dtype=np.float128)\n",
    "    \n",
    "    for iter_ in range(max_iter):\n",
    "        shuffle(train_list)\n",
    "        for samp,element in enumerate(train_list):\n",
    "            i,j = element[0],element[1]\n",
    "            e = -np.dot(p[i,:],(q[:,j]))+R_train[i,j]\n",
    "            p[i,:] += lr*(2*e*q[:,j]-lam*p[i,:])\n",
    "            q[:,j] += lr*(2*e*p[i,:]-lam*q[:,j])\n",
    "        R_pred = get_pred(p,q,train_list)\n",
    "        print_loss(R_pred,R_train,train_list,'train')\n",
    "    return p,q\n",
    "\n",
    "\n",
    "\n",
    "def get_pred(p,q,test_list):\n",
    "    \"\"\"\n",
    "    get predictions of the trained model on test or train data\n",
    "    \"\"\"\n",
    "    R_pred = lil_matrix((l, w))\n",
    "    for element in test_list:\n",
    "        i,j = element[0],element[1]\n",
    "        R_pred[i,j] = np.dot(p[i,:],(q[:,j]))\n",
    "#         R_train = lil_matrix((138493, 26744))\n",
    "    return R_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getMRR(user_ratings,R_test,R_pred,test_or_train):\n",
    "    \"\"\"\n",
    "    get MMR values\n",
    "    \"\"\"\n",
    "    total = 0.0\n",
    "    for userID0 in user_ratings.keys():\n",
    "        k = int(len(user_ratings[userID0])/2)\n",
    "        mrr = 0.0\n",
    "        movie_list = []\n",
    "        if test_or_train=='test':\n",
    "            start,end = k,len(user_ratings[userID0])\n",
    "        elif test_or_train=='train':\n",
    "            start,end = 0,k\n",
    "        else:\n",
    "            raise ValueError('please try either train or test mode')\n",
    "        for i in range(start,end):\n",
    "            #movieID, rating <- user_ratings[userID0][i]\n",
    "            movieID, rating = user_ratings[userID0][i][0], user_ratings[userID0][i][1]\n",
    "             #R_test[movieID, userID0]>=3.0:\n",
    "            movie_list.append((movieID,R_pred[userID0,movieID]))\n",
    "        movie_list.sort(key=lambda tup: tup[1])  # reverse or not?\n",
    "        ct = 0.0\n",
    "        for rank,i in enumerate(movie_list):\n",
    "            rank+=1.0\n",
    "            movieID, pred = i[0],i[1]\n",
    "            if R_test[userID0,movieID]>=3.0:\n",
    "                mrr += 1/rank\n",
    "                ct+=1.0\n",
    "        if mrr!=0 and ct!=0:\n",
    "            total += mrr/ct\n",
    "    total = total/len(user_ratings.keys())\n",
    "    print(test_or_train,' mrr ',total)\n",
    "    return total\n",
    "\n",
    "\n",
    "def print_loss(R_test_pred,R_test,data_list,mode):\n",
    "    \"\"\"\n",
    "    print root means dqure loss on the train or test data, depending on the inputs, mode is either 'train' or 'test'\n",
    "    \"\"\"\n",
    "    R_e = lil_matrix((l, w))\n",
    "    for element in data_list:\n",
    "        i,j = element[0],element[1]\n",
    "        R_e[i,j] = R_test[i,j]-R_test_pred[i,j]\n",
    "    loss = norm(R_e)/np.sqrt(len(data_list))\n",
    "    print(mode,' mse ',loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_train = R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_train = R_train[:-1000000,:-100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_list = R_train.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107133"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "for i in zip(tr_list[0],tr_list[1]):\n",
    "    train_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 starting of  1 r =  1 lam =  0.01\n",
      "train  mse  3.96441889007\n",
      "train  mse  3.75092736479\n",
      "train  mse  3.25721965995\n",
      "train  mse  2.83475250833\n",
      "train  mse  2.50723405369\n",
      "train  mse  2.2474575931\n",
      "train  mse  2.04044072815\n",
      "train  mse  1.87736634987\n",
      "train  mse  1.74713272078\n",
      "train  mse  1.6427837007\n",
      "train  mse  1.55819789924\n",
      "train  mse  1.489732365\n",
      "train  mse  1.4328451562\n",
      "train  mse  1.38574134735\n",
      "train  mse  1.34751766201\n",
      "train  mse  1.34751766201\n"
     ]
    }
   ],
   "source": [
    "### specify training parameters here\n",
    "id_no = '1'\n",
    "pflag = '1'\n",
    "lr = 0.01  # learning rate\n",
    "max_iter= 15 # maximum number of epocs to be trained on\n",
    "results_train = {}\n",
    "results_test = {}\n",
    "complete =0 \n",
    "\n",
    "r_list = [1]\n",
    "lam_list = [0.01]\n",
    "#lam_list = [lam_list_full[int(id_no)-1]]\n",
    "# m2i,ratings_lines = read_file('ml-20m/ratings.csv')\n",
    "# train_list,test_list,R_train,R_test,user_ratings = split_train_test(ratings_lines)\n",
    "\n",
    "\n",
    "# 2 for loops for grid search, one loop for rank values, one loop for lambda valuesS\n",
    "for r in r_list:\n",
    "    for lam in lam_list:\n",
    "        complete+=1\n",
    "        print(complete,'starting of ',len(r_list)*len(lam_list),'r = ',r,'lam = ',lam)\n",
    "        p,q = train(R_train,train_list,r,max_iter,lam,lr)\n",
    "#         R_test_pred = get_pred(p,q,test_list)\n",
    "        R_train_pred = get_pred(p,q,train_list)\n",
    "#         loss_test = print_loss(R_test_pred,R_test,test_list,'test')\n",
    "        loss_train = print_loss(R_train_pred,R_train,train_list,'train')\n",
    "#         MRR_test = getMRR(user_ratings,R_test,R_test_pred,'test')\n",
    "#         MRR_train = getMRR(user_ratings,R_train,R_train_pred,'train')\n",
    "\n",
    "#         results_train[(r,lam)] = (MRR_train,loss_train)\n",
    "#         results_test[(r,lam)] = (MRR_test,loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
